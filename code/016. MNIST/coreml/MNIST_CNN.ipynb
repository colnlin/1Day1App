{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# (Making sure) Set backend as tensorflow\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "Keras has helper functions to setup the MNIST dataset. Let us create the train and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28) y_train: (60000,)\n",
      "X_test : (10000, 28, 28) y_test : (10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print \"X_train:\", X_train.shape, \"y_train:\", y_train.shape\n",
    "print \"X_test :\", X_test.shape, \"y_test :\", y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-format Input\n",
    "Let us reshape the data into TensorFlow friendly format: (batch_size, num_rows, num_cols, num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28, 1) X_test: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "num_rows = 28\n",
    "num_cols = 28\n",
    "num_channels = 1\n",
    "num_classes = 10\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], num_rows, num_cols, num_channels).astype(np.float32) / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], num_rows, num_cols, num_channels).astype(np.float32) / 255\n",
    "\n",
    "print \"X_train:\", X_train.shape, \"X_test:\", X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-format Output\n",
    "The output is classification among ten classes [0..9]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: (60000, 10) y_test: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "print \"y_train:\", y_train.shape, \"y_test:\", y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7\n"
     ]
    }
   ],
   "source": [
    "im = X_train[1001,:,:,0]\n",
    "plt.imshow(im,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print 'Label:',np.nonzero(y_train[1001,:])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    }
   ],
   "source": [
    "im = X_train[1,:,:,0]\n",
    "plt.imshow(im,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print 'Label:',np.nonzero(y_train[5036,:])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128, (1, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 128)         8320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 94,602\n",
      "Trainable params: 94,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 36s - loss: 0.6229 - acc: 0.7940 - val_loss: 0.1398 - val_acc: 0.9584\n",
      "Epoch 2/10\n",
      " - 35s - loss: 0.1914 - acc: 0.9397 - val_loss: 0.0786 - val_acc: 0.9765\n",
      "Epoch 3/10\n",
      " - 35s - loss: 0.1379 - acc: 0.9568 - val_loss: 0.0611 - val_acc: 0.9819\n",
      "Epoch 4/10\n",
      " - 35s - loss: 0.1137 - acc: 0.9643 - val_loss: 0.0547 - val_acc: 0.9839\n",
      "Epoch 5/10\n",
      " - 35s - loss: 0.0976 - acc: 0.9698 - val_loss: 0.0439 - val_acc: 0.9881\n",
      "Epoch 6/10\n",
      " - 35s - loss: 0.0844 - acc: 0.9727 - val_loss: 0.0408 - val_acc: 0.9882\n",
      "Epoch 7/10\n",
      " - 35s - loss: 0.0778 - acc: 0.9752 - val_loss: 0.0363 - val_acc: 0.9899\n",
      "Epoch 8/10\n",
      " - 35s - loss: 0.0720 - acc: 0.9768 - val_loss: 0.0349 - val_acc: 0.9901\n",
      "Epoch 9/10\n",
      " - 35s - loss: 0.0669 - acc: 0.9792 - val_loss: 0.0318 - val_acc: 0.9905\n",
      "Epoch 10/10\n",
      " - 35s - loss: 0.0638 - acc: 0.9798 - val_loss: 0.0325 - val_acc: 0.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x115f38e50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Dropouts for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in model.layers:\n",
    "    if type(k) is keras.layers.Dropout:\n",
    "        model.layers.remove(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 128)         8320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 94,602\n",
      "Trainable params: 94,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnistCNN.h5 saved\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('mnistCNN.h5')\n",
    "print('mnistCNN.h5 saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : conv2d_1_input, <keras.engine.topology.InputLayer object at 0x1167ecc90>\n",
      "1 : conv2d_1, <keras.layers.convolutional.Conv2D object at 0x1167ec6d0>\n",
      "2 : conv2d_1__activation__, <keras.layers.core.Activation object at 0x12e7413d0>\n",
      "3 : max_pooling2d_1, <keras.layers.pooling.MaxPooling2D object at 0x1167ec590>\n",
      "4 : conv2d_2, <keras.layers.convolutional.Conv2D object at 0x1167ec390>\n",
      "5 : conv2d_2__activation__, <keras.layers.core.Activation object at 0x12e4d38d0>\n",
      "6 : max_pooling2d_2, <keras.layers.pooling.MaxPooling2D object at 0x1167ece50>\n",
      "7 : conv2d_3, <keras.layers.convolutional.Conv2D object at 0x116a3b790>\n",
      "8 : conv2d_3__activation__, <keras.layers.core.Activation object at 0x12e4d3b10>\n",
      "9 : max_pooling2d_3, <keras.layers.pooling.MaxPooling2D object at 0x11681f490>\n",
      "10 : flatten_1, <keras.layers.core.Flatten object at 0x116a53f50>\n",
      "11 : dense_1, <keras.layers.core.Dense object at 0x12e43d7d0>\n",
      "12 : dense_1__activation__, <keras.layers.core.Activation object at 0x12e4d37d0>\n",
      "13 : dense_2, <keras.layers.core.Dense object at 0x12e460b90>\n",
      "14 : dense_2__activation__, <keras.layers.core.Activation object at 0x12e4d3b50>\n",
      "mnistCNN.mlmodel saved\n"
     ]
    }
   ],
   "source": [
    "import coremltools\n",
    "\n",
    "output_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "scale = 1/255.\n",
    "coreml_model = coremltools.converters.keras.convert('./mnistCNN.h5',\n",
    "                                                   input_names='image',\n",
    "                                                   image_input_names='image',\n",
    "                                                   output_names='output',\n",
    "                                                   class_labels=output_labels,\n",
    "                                                   image_scale=scale)\n",
    "\n",
    "coreml_model.author = 'iOSDevLog'\n",
    "coreml_model.license = 'MIT'\n",
    "coreml_model.short_description = 'Model to classify hand written digit'\n",
    "\n",
    "coreml_model.input_description['image'] = 'Grayscale image of hand written digit'\n",
    "coreml_model.output_description['output'] = 'Predicted digit'\n",
    "\n",
    "coreml_model.save('mnistCNN.mlmodel')\n",
    "print('mnistCNN.mlmodel saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
